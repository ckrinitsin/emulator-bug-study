architecture: 0.877
files: 0.741
debug: 0.723
ppc: 0.717
device: 0.704
mistranslation: 0.698
semantic: 0.665
TCG: 0.655
performance: 0.644
graphic: 0.640
permissions: 0.551
PID: 0.544
register: 0.478
vnc: 0.474
VMM: 0.464
risc-v: 0.445
network: 0.429
socket: 0.426
hypervisor: 0.387
boot: 0.382
arm: 0.351
i386: 0.350
x86: 0.330
virtual: 0.295
KVM: 0.266
user-level: 0.254
kernel: 0.234
assembly: 0.207
peripherals: 0.205
--------------------
debug: 0.761
architecture: 0.286
mistranslation: 0.220
x86: 0.180
TCG: 0.125
files: 0.121
i386: 0.053
PID: 0.030
register: 0.026
semantic: 0.023
virtual: 0.018
arm: 0.012
assembly: 0.007
VMM: 0.007
network: 0.006
socket: 0.005
permissions: 0.005
kernel: 0.004
device: 0.004
hypervisor: 0.004
risc-v: 0.003
boot: 0.003
ppc: 0.002
performance: 0.002
vnc: 0.002
peripherals: 0.002
user-level: 0.002
graphic: 0.001
KVM: 0.001

Tricore: wrong implementation of OPC1_16_SRO_LD_H in target/tricore/translate.c
Description of problem:
The translation of the 16bit opcode LD.HD[15], A[b], off4 (SRO) is not done properly.
Page 210 of
https://www.infineon.com/dgdl/Infineon-TC2xx_Architecture_vol2-UM-v01_00-EN.pdf?fileId=5546d46269bda8df0169ca1bf33124a8
as 
D[15] = sign_ext(M(A[b] + zero_ext(2 * off4), half-word));
1) Implemented in target/tricore/translate.c as
    case OPC1_16_SRO_LD_H:
        gen_offset_ld(ctx, cpu_gpr_d[15], cpu_gpr_a[r2], address, MO_LESW);
        break;

2) Should be 
    case OPC1_16_SRO_LD_H:
        gen_offset_ld(ctx, cpu_gpr_d[15], cpu_gpr_a[r2], address * 2, MO_LESW);
        break;

Detected: 
testsuite gcc9.1.0 delta analysis of Infineon Instruction Set Simulator vs. qemu-system-tricore
fix from 2) is successfull

Confidence Level for bugfix high.
Is according to spec. and in line with reference Instruction Set Simulator from Infineon.

Motivation
Reexecution of gcc/g++/libstdc++ testsuites with qemu

I honor the implementation work which was done by bkoppelmann, vo_lumit@gmx.de
