semantic: 0.170
device: 0.137
other: 0.126
files: 0.096
network: 0.065
PID: 0.058
vnc: 0.056
performance: 0.052
permissions: 0.048
graphic: 0.045
debug: 0.042
socket: 0.038
boot: 0.038
KVM: 0.029
debug: 0.572
other: 0.073
PID: 0.047
files: 0.047
semantic: 0.047
device: 0.043
network: 0.033
performance: 0.030
socket: 0.030
boot: 0.025
graphic: 0.017
permissions: 0.014
vnc: 0.013
KVM: 0.008

VM will not resume on GlusterFS

oVirt uses libvirt to run QEMU.
Images are passed to QEMU as files, not file descriptors.
When running images from a GlusterFS, the file descriptors may get invalidated because of network problems or the glusterfs process being restarted.
In this case, the VM goes into paused state.
When trying to resume the VM ('cont' command), QEMU uses the same invalidated file descriptors throwing a:
"block I/O error in device 'drive-virtio-disk0': Transport endpoint is not connected (107)".

Please check file-descriptors and reopen image file on 'cont' event in QEMU.
Thanks.

References:

[1] http://lists.nongnu.org/archive/html/qemu-devel/2015-03/msg01269.html
[2] https://bugzilla.redhat.com/show_bug.cgi?id=1058300

We can't just reopen files, we don't know what state they are in. Any data that has been written to the image between the last flush and the point where gluster made the fd invalid may be there or may be missing. If any data is missing, we can't continue the guest or you'll get data corruption.

The correct fix for resuming after I/O errors is on gluster. As long as it invalidates the fd, without a way to resume, there is no way for qemu to correctly continue after an error.

Hi Kevin,

I understand. In this case (where the gluster process was killed or crashed) I guess the best option would be to poweroff and restart the VM, which can be done client-side (ovirt + libvirt)

Please mark as "Won't fix".

Thanks. 

Marking as "Won't Fix" according to the last comment.

