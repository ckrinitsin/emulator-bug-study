semantic: 0.974
graphic: 0.973
permissions: 0.973
performance: 0.967
assembly: 0.963
virtual: 0.961
register: 0.960
debug: 0.959
device: 0.956
architecture: 0.950
arm: 0.949
peripherals: 0.943
kernel: 0.941
PID: 0.938
network: 0.931
socket: 0.929
TCG: 0.919
vnc: 0.918
ppc: 0.918
risc-v: 0.916
files: 0.909
boot: 0.903
mistranslation: 0.900
user-level: 0.898
VMM: 0.893
KVM: 0.830
hypervisor: 0.824
i386: 0.804
x86: 0.781

Nested vIOMMU PCI Passthrough kernel panics
Description of problem:
In an effort to test vIOMMU according to <https://wiki.qemu.org/Features/VT-d> I've run into a kernel panic on an L2 guest receiving the L1 hypervisor's PCI passed virtual macvtap hostdev. Upon an `ifup` inside the L2 guest, on the network device passed through from the L1 host, the following kernel panic occurs and the L2 guest reboots:

```
[  OK  ] Started ifup@enp0s2.service - ifup for enp0s2.
[  OK  ] Started ifup@enp0s3.service - ifup for enp0s3.[   24.019839] audit: type=1400 audit(1707113302.472:9): apparmor="STATUS" operation="profile_load" profile="unconfined" name="/usr/bin/man" pid=457 comm="apparmor_parser"

         Starting networking.service - Raise network interfaces...
[   24.255671] audit: type=1400 audit(1707113302.472:10): apparmor="STATUS" operation="profile_load" profile="unconfined" name="man_filter" pid=457 comm="apparmor_parser"
[  OK  ] Finished systemd-tmpfiles-…te Volatile Files and Directories.
[   24.361355] audit: type=1400 audit(1707113302.472:11): apparmor="STATUS" operation="profile_load" profile="unconfined" name="man_groff" pid=457 comm="apparmor_parser"
         Starting systemd-timesyncd… - Network Time Synchronization...
         Starting systemd-update-ut…rd System Boot/Shutdown in UTMP...
[  OK  ] Finished systemd-update-ut…cord System Boot/Shutdown in UTMP.
[  OK  ] Finished networking.service - Raise network interfaces.
[  OK  ] Reached target network.target - Network.
[  OK  ] Started systemd-timesyncd.…0m - Network Time Synchronization.
[  OK  ] Reached target sysinit.target - System Initialization.
[  OK  ] Started etckeeper.timermit of changes in /etc directory.
[  OK  ] Started systemd-tmpfiles-c… Cleanup of Temporary Directories.
[  OK  ] Reached target time-set.target - System Time Set.
[  OK  ] Started apt-daily.timer - Daily apt download activities.[   46.187450] rcu: INFO: rcu_preempt self-detected stall on CPU
[   46.187522] rcu:     0-...!: (5250 ticks this GP) idle=3774/1/0x4000000000000000 softirq=12350/12350 fqs=0
[   46.187522]  (t=5250 jiffies g=8669 q=7 ncpus=1)
[   46.187522] rcu: rcu_preempt kthread timer wakeup didn't happen for 5249 jiffies! g8669 f0x0 RCU_GP_WAIT_FQS(5) ->state=0x402
[   46.187522] rcu:     Possible timer handling issue on cpu=0 timer-softirq=2282
[   46.187522] rcu: rcu_preempt kthread starved for 5250 jiffies! g8669 f0x0 RCU_GP_WAIT_FQS(5) ->state=0x402 ->cpu=0
[   46.187522] rcu:     Unless rcu_preempt kthread gets sufficient CPU time, OOM is now expected behavior.
[   46.187522] rcu: RCU grace-period kthread stack dump:
[   46.187522] task:rcu_preempt     state:I stack:0     pid:15    ppid:2      flags:0x00004000
[   46.187522] Call Trace:
[   46.187522]  <TASK>
[   46.187522]  __schedule+0x34d/0x9e0
[   46.187522]  ? rcu_gp_cleanup+0x460/0x460
[   46.187522]  schedule+0x5a/0xd0
[   46.187522]  schedule_timeout+0x94/0x150
[   46.187522]  ? __bpf_trace_tick_stop+0x10/0x10
[   46.187522]  rcu_gp_fqs_loop+0x141/0x550
[   46.187522]  rcu_gp_kthread+0xd0/0x190
[   46.187522]  kthread+0xda/0x100
[   46.187522]  ? kthread_complete_and_exit+0x20/0x20
[   46.187522]  ret_from_fork+0x22/0x30
[   46.187522]  </TASK>
[   46.187522] rcu: Stack dump where RCU GP kthread last ran:
[   46.187522] CPU: 0 PID: 487 Comm: ip Not tainted 6.1.0-17-amd64 #1  Debian 6.1.69-1
[   46.187522] Hardware name: QEMU Standard PC (Q35 + ICH9, 2009), BIOS Arch Linux 1.16.3-1-1 04/01/2014
[   46.187522] RIP: 0010:virtqueue_get_buf_ctx_split+0x94/0xd0 [virtio_ring]
[   46.187522] Code: 42 fe ff ff 0f b7 43 58 83 c0 01 66 89 43 58 f6 83 80 00 00 00 01 75 12 80 7b 4a 00 48 8b 4b 70 8b 53 60 74 0f 66 87 44 51 04 <48> 89 e8 5b 5d c3 cc cc cc cc 66 89 44 51 04 0f ae f0 48 89 e8 5b
[   46.187522] RSP: 0018:ffff960c408135c8 EFLAGS: 00000246
[   46.187522] RAX: 0000000000000000 RBX: ffff88e04e976100 RCX: 0000000000000001
[   46.187522] RDX: 0000000000000000 RSI: ffff960c408135e4 RDI: ffff88e04e976100
[   46.187522] RBP: 0000000000000000 R08: 0000000000000004 R09: ffff88e0034fa980
[   46.187522] R10: 0000000000000003 R11: ffff960c40813628 R12: 0000000000000002
[   46.187522] R13: 0000000000000000 R14: 0000000000000000 R15: 0000000000000001
[   46.187522] FS:  00007f11d16da2c0(0000) GS:ffff88e07dc00000(0000) knlGS:0000000000000000
[   46.187522] CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033
[   46.187522] CR2: 00007f11d17ff8d0 CR3: 0000000004ac6000 CR4: 00000000000006f0
[   46.187522] Call Trace:
[   46.187522]  <IRQ>
[   46.187522]  ? rcu_check_gp_kthread_starvation+0xec/0xfd
[   46.187522]  ? rcu_sched_clock_irq.cold+0xe3/0x459
[   46.187522]  ? update_load_avg+0x7e/0x780
[   46.187522]  ? sched_slice+0x87/0x140
[   46.187522]  ? timekeeping_update+0xdd/0x130
[   46.187522]  ? timekeeping_advance+0x377/0x570
[   46.187522]  ? update_process_times+0x70/0xb0
[   46.187522]  ? tick_sched_handle+0x22/0x60
[   46.187522]  ? tick_sched_timer+0x63/0x80
[   46.187522]  ? tick_sched_do_timer+0xa0/0xa0
[   46.187522]  ? __hrtimer_run_queues+0x112/0x2b0
[   46.187522]  ? hrtimer_interrupt+0xf4/0x210
[   46.187522]  ? __sysvec_apic_timer_interrupt+0x5d/0x110
[   46.187522]  ? sysvec_apic_timer_interrupt+0x69/0x90
[   46.187522]  </IRQ>
[   46.187522]  <TASK>
[   46.187522]  ? asm_sysvec_apic_timer_interrupt+0x16/0x20
[   46.187522]  ? virtqueue_get_buf_ctx_split+0x94/0xd0 [virtio_ring]
[   46.187522]  virtnet_send_command+0x18e/0x1e0 [virtio_net]
[   46.187522]  virtnet_set_rx_mode+0xd4/0x2d0 [virtio_net]
[   46.187522]  __dev_open+0x12b/0x1a0
[   46.187522]  __dev_change_flags+0x1d2/0x240
[   46.187522]  dev_change_flags+0x22/0x60
[   46.187522]  do_setlink+0x37c/0x12b0
[   46.187522]  ? __nla_validate_parse+0x61/0xc00
[   46.187522]  __rtnl_newlink+0x623/0x9e0
[   46.187522]  ? __kmem_cache_alloc_node+0x191/0x2a0
[   46.187522]  rtnl_newlink+0x43/0x70
[   46.187522]  rtnetlink_rcv_msg+0x14e/0x3b0
[   46.187522]  ? __kmem_cache_alloc_node+0x191/0x2a0
[   46.187522]  ? __alloc_skb+0x88/0x1a0
[   46.187522]  ? rtnl_calcit.isra.0+0x140/0x140
[   46.187522]  netlink_rcv_skb+0x51/0x100
[   46.187522]  netlink_unicast+0x24a/0x390
[   46.187522]  netlink_sendmsg+0x250/0x4c0
[   46.187522]  __sock_sendmsg+0x5f/0x70
[   46.187522]  ____sys_sendmsg+0x277/0x2f0
[   46.187522]  ? copy_msghdr_from_user+0x7d/0xc0
[   46.187522]  ___sys_sendmsg+0x9a/0xe0
[   46.187522]  __sys_sendmsg+0x76/0xc0
[   46.187522]  do_syscall_64+0x5b/0xc0
[   46.187522]  ? exit_to_user_mode_prepare+0x40/0x1e0
[   46.187522]  ? syscall_exit_to_user_mode+0x27/0x40
[   46.187522]  ? do_syscall_64+0x67/0xc0
[   46.187522]  ? do_user_addr_fault+0x1b0/0x580
[   46.187522]  ? exit_to_user_mode_prepare+0x40/0x1e0
[   46.187522]  entry_SYSCALL_64_after_hwframe+0x64/0xce
[   46.187522] RIP: 0033:0x7f11d1811af0
[   46.187522] Code: 00 f7 d8 64 89 02 48 c7 c0 ff ff ff ff eb b7 66 2e 0f 1f 84 00 00 00 00 00 90 80 3d f1 fa 0c 00 00 74 17 b8 2e 00 00 00 0f 05 <48> 3d 00 f0 ff ff 77 58 c3 0f 1f 80 00 00 00 00 48 83 ec 28 89 54
[   46.187522] RSP: 002b:00007ffe21b533a8 EFLAGS: 00000202 ORIG_RAX: 000000000000002e
[   46.187522] RAX: ffffffffffffffda RBX: 0000000000000003 RCX: 00007f11d1811af0
[   46.187522] RDX: 0000000000000000 RSI: 00007ffe21b53410 RDI: 0000000000000003
[   46.187522] RBP: 0000000000000003 R08: 0000000065c07b57 R09: 00005580e154e2a0
[   46.187522] R10: 00007ffe21b52e34 R11: 0000000000000202 R12: 0000000065c07b58
[   46.187522] R13: 00005580e016e020 R14: 0000000000000001 R15: 0000000000000000
[   46.187522]  </TASK>
[   46.187522] CPU: 0 PID: 487 Comm: ip Not tainted 6.1.0-17-amd64 #1  Debian 6.1.69-1
[   46.187522] Hardware name: QEMU Standard PC (Q35 + ICH9, 2009), BIOS Arch Linux 1.16.3-1-1 04/01/2014
[   46.187522] RIP: 0010:virtqueue_get_buf_ctx_split+0x94/0xd0 [virtio_ring]
[   46.187522] Code: 42 fe ff ff 0f b7 43 58 83 c0 01 66 89 43 58 f6 83 80 00 00 00 01 75 12 80 7b 4a 00 48 8b 4b 70 8b 53 60 74 0f 66 87 44 51 04 <48> 89 e8 5b 5d c3 cc cc cc cc 66 89 44 51 04 0f ae f0 48 89 e8 5b
[   46.187522] RSP: 0018:ffff960c408135c8 EFLAGS: 00000246
[   46.187522] RAX: 0000000000000000 RBX: ffff88e04e976100 RCX: 0000000000000001
[   46.187522] RDX: 0000000000000000 RSI: ffff960c408135e4 RDI: ffff88e04e976100
[   46.187522] RBP: 0000000000000000 R08: 0000000000000004 R09: ffff88e0034fa980
[   46.187522] R10: 0000000000000003 R11: ffff960c40813628 R12: 0000000000000002
[   46.187522] R13: 0000000000000000 R14: 0000000000000000 R15: 0000000000000001
[   46.187522] FS:  00007f11d16da2c0(0000) GS:ffff88e07dc00000(0000) knlGS:0000000000000000
[   46.187522] CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033
[   46.187522] CR2: 00007f11d17ff8d0 CR3: 0000000004ac6000 CR4: 00000000000006f0
[   46.187522] Call Trace:
[   46.187522]  <IRQ>
[   46.187522]  ? rcu_dump_cpu_stacks+0xa4/0xe0
[   46.187522]  ? rcu_sched_clock_irq.cold+0xe8/0x459
[   46.187522]  ? update_load_avg+0x7e/0x780
[   46.187522]  ? sched_slice+0x87/0x140
[   46.187522]  ? timekeeping_update+0xdd/0x130
[   46.187522]  ? timekeeping_advance+0x377/0x570
[   46.187522]  ? update_process_times+0x70/0xb0
[   46.187522]  ? tick_sched_handle+0x22/0x60
[   46.187522]  ? tick_sched_timer+0x63/0x80
[   46.187522]  ? tick_sched_do_timer+0xa0/0xa0
[   46.187522]  ? __hrtimer_run_queues+0x112/0x2b0
[   46.187522]  ? hrtimer_interrupt+0xf4/0x210
[   46.187522]  ? __sysvec_apic_timer_interrupt+0x5d/0x110
[   46.187522]  ? sysvec_apic_timer_interrupt+0x69/0x90
[   46.187522]  </IRQ>
[   46.187522]  <TASK>
[   46.187522]  ? asm_sysvec_apic_timer_interrupt+0x16/0x20
[   46.187522]  ? virtqueue_get_buf_ctx_split+0x94/0xd0 [virtio_ring]
[   46.187522]  virtnet_send_command+0x18e/0x1e0 [virtio_net]
[   46.187522]  virtnet_set_rx_mode+0xd4/0x2d0 [virtio_net]
[   46.187522]  __dev_open+0x12b/0x1a0
[   46.187522]  __dev_change_flags+0x1d2/0x240
[   46.187522]  dev_change_flags+0x22/0x60
[   46.187522]  do_setlink+0x37c/0x12b0
[   46.187522]  ? __nla_validate_parse+0x61/0xc00
[   46.187522]  __rtnl_newlink+0x623/0x9e0
[   46.187522]  ? __kmem_cache_alloc_node+0x191/0x2a0
[   46.187522]  rtnl_newlink+0x43/0x70
[   46.187522]  rtnetlink_rcv_msg+0x14e/0x3b0
[   46.187522]  ? __kmem_cache_alloc_node+0x191/0x2a0
[   46.187522]  ? __alloc_skb+0x88/0x1a0
[   46.187522]  ? rtnl_calcit.isra.0+0x140/0x140
[   46.187522]  netlink_rcv_skb+0x51/0x100
[   46.187522]  netlink_unicast+0x24a/0x390
[   46.187522]  netlink_sendmsg+0x250/0x4c0
[   46.187522]  __sock_sendmsg+0x5f/0x70
[   46.187522]  ____sys_sendmsg+0x277/0x2f0
[   46.187522]  ? copy_msghdr_from_user+0x7d/0xc0
[   46.187522]  ___sys_sendmsg+0x9a/0xe0
[   46.187522]  __sys_sendmsg+0x76/0xc0
[   46.187522]  do_syscall_64+0x5b/0xc0
[   46.187522]  ? exit_to_user_mode_prepare+0x40/0x1e0
[   46.187522]  ? syscall_exit_to_user_mode+0x27/0x40
[   46.187522]  ? do_syscall_64+0x67/0xc0
[   46.187522]  ? do_user_addr_fault+0x1b0/0x580
[   46.187522]  ? exit_to_user_mode_prepare+0x40/0x1e0
[   46.187522]  entry_SYSCALL_64_after_hwframe+0x64/0xce
[   46.187522] RIP: 0033:0x7f11d1811af0
[   46.187522] Code: 00 f7 d8 64 89 02 48 c7 c0 ff ff ff ff eb b7 66 2e 0f 1f 84 00 00 00 00 00 90 80 3d f1 fa 0c 00 00 74 17 b8 2e 00 00 00 0f 05 <48> 3d 00 f0 ff ff 77 58 c3 0f 1f 80 00 00 00 00 48 83 ec 28 89 54
[   46.187522] RSP: 002b:00007ffe21b533a8 EFLAGS: 00000202 ORIG_RAX: 000000000000002e
[   46.187522] RAX: ffffffffffffffda RBX: 0000000000000003 RCX: 00007f11d1811af0
[   46.187522] RDX: 0000000000000000 RSI: 00007ffe21b53410 RDI: 0000000000000003
[   46.187522] RBP: 0000000000000003 R08: 0000000065c07b57 R09: 00005580e154e2a0
[   46.187522] R10: 00007ffe21b52e34 R11: 0000000000000202 R12: 0000000065c07b58
[   46.187522] R13: 00005580e016e020 R14: 0000000000000001 R15: 0000000000000000
[   46.187522]  </TASK>
```
Steps to reproduce:
1. Create the following nested passthrough configuration
2. Attempt to configure the L1 network hostdev interface inside the L2 guest

Any attempt will cause the kernel panics documented.
Additional information:
#
