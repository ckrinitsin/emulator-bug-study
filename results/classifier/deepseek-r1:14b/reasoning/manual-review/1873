<think>
Okay, so I've got this problem where a VM crashes when changing the MTU on a virtual function after setting a higher MTU on the physical function. Let's break down what might be happening here.

First, the user created a VM using the igb driver for network. They changed the PF (Physical Function) MTU to 9000, allocated some virtual functions, and then tried changing the MTU on one of those VFs, which caused the VM to crash with a fatal exception in interrupt.

I know that MTU settings affect how data is sent over the network, especially for larger frames. The igb driver is from Intel, so I should check if there are known issues with it regarding high MTUs and virtual functions.

The kernel panic mentions a fatal exception in an interrupt, which suggests something went wrong during interrupt handling. Maybe the MTU change caused some unexpected behavior in how network packets are processed or passed to the VM.

I should look into whether changing the VF's MTU after modifying the PF's MTU is supported. Perhaps there's a bug where the igb driver doesn't handle this scenario correctly, leading to an inconsistency between the PF and VF configurations.

Another thought: when you change the MTU on the physical function, it affects how the hypervisor or the parent partition handles traffic. If the virtual functions aren't properly updated or if their queues aren't reconfigured, this could lead to miscommunication with the VM's network stack.

I wonder if there are specific igb driver settings or parameters that need to be adjusted when dealing with large MTUs and SR-IOV (which is what allocating VFs typically uses). Maybe there's a missing step in configuring the VF after changing the PF's MTU, like reinitializing certain aspects of the network interface.

I should also consider checking if this issue has been reported before. Looking up Intel's support or community forums for similar problems might reveal known workarounds or patches. If it's a kernel bug, there might be updates or specific versions where this issue is fixed.

In summary, possible causes include driver bugs related to MTU changes on VFs after PF configuration, improper handling of large frames, or issues with interrupt processing when network parameters are altered. The solution might involve checking for driver updates, ensuring proper reconfiguration steps after each MTU change, or adjusting specific settings in the hypervisor or OS to handle these cases better.
</think>

The issue you're encountering is likely due to a bug in the igb driver where changing the MTU on a virtual function (VF) after modifying the physical function (PF)'s MTU causes an interrupt exception. Here's how you can address it:

### Step-by-Step Explanation and Solution:

1. **Check for Driver Updates:**
   - Ensure that your system is running the latest version of the igb driver from Intel. Sometimes, such bugs are fixed in newer releases.

2. **Reconfigure Virtual Functions Properly:**
   - After changing the MTU on the PF, you need to reinitialize the VFs. This might involve resetting or recreating the virtual functions rather than just changing their MTU settings.

3. **Use Appropriate Commands:**
   - When adjusting the MTU, use specific commands that handle SR-IOV (Single Root I/O Virtualization) correctly. For example:
     ```bash
     # After setting PF MTU to 9000
     ip link set dev <PF-interface> mtu 9000

     # Then for each VF, reset and reconfigure
     echo "8" > /sys/bus/pci/devices/<VF-pci-address>/sriov_numvfs
     ifconfig <VF-interface> mtu 9000 up
     ```

4. **Avoid Partial Configuration:**
   - Ensure that all aspects of the network interface are consistently updated when modifying MTU, especially in a SR-IOV setup.

5. **Consult Documentation and Forums:**
   - Check Intel's documentation for known issues with igb and high MTUs. Engage with community forums or support channels to see if others have encountered similar problems.

### Conclusion:
The crash is likely due to improper handling of the VF after an MTU change on the PF. Updating the driver, ensuring correct reconfiguration steps, and following best practices for SR-IOV should resolve the issue.