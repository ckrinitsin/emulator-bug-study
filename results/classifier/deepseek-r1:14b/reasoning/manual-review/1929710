<think>
Alright, so I'm trying to figure out why this error is happening. The user mentioned that when swap_volume fails, the original device gets detached, but they expect it to leave the original attached. Let me break this down.

First, looking at the logs, the error is "virDomainGetBlockJobInfo() failed". That sounds like a libvirt issue, maybe something wrong with how the hypervisor is handling block jobs. The fact that it's failing on two different build changes (786588 and 792322) suggests there might be some regression here.

The environment is OpenStack master using libvirt + QEMU without KVM in the gate, so I'm thinking this could be a problem with how the hypervisor interacts with block devices. The storage type is default qcow2 images, which are common but can sometimes have issues if not configured properly.

I need to consider what swap_volume does. It's likely trying to attach or modify a swap volume on the instance. If it fails, maybe the detachment isn't handled correctly. Looking at the logs from screen-n-cpu.txt, there might be more details about why the block job is failing—perhaps timeout issues, permissions, or device not found.

I should check if there are any recent changes in the code that affect how swap volumes are handled, especially around libvirt interactions. Maybe the error is due to an incorrect XML configuration for the virtual machine's storage devices or a problem with how the block job is managed.

Also, since this happens across different hypervisors (ovh-bhs1 and rax-iad), it might not be specific to hardware but rather a software bug. I'll look into any known issues in libvirt related to block jobs failing, especially when dealing with swap volumes or similar operations.

To debug further, perhaps the logs could show more specifics about why virDomainGetBlockJobInfo is failing—like an error code or message that can be traced back to a known issue. Maybe adding more logging around this function call could provide insight into what's going wrong.

In summary, I think the problem lies in how swap_volume operations are handled by libvirt, leading to incorrect device detachment on failure. Investigating the specific cause of virDomainGetBlockJobInfo failure and ensuring proper cleanup when swap_volume fails should help resolve this.
</think>

The issue you're experiencing with `virDomainGetBlockJobInfo() failed` causing the original device to be detached instead of leaving it attached likely stems from a problem in how the hypervisor (libvirt) handles block operations, particularly during swap volume failures. 

To address this:

1. **Investigate Error Logs**: Look for more detailed error messages in `screen-n-cpu.txt` that might explain why the block job failed.

2. **Check Code Changes**: Review any recent changes related to swap volume handling or libvirt interactions in your OpenStack codebase, as issues might have been introduced there.

3. **Verify Block Job Handling**: Ensure that when swap_volume fails, the original device isn't detached. This might involve correcting how the block job is managed or adding error handling to prevent unintended detachments.

4. **Update and Test**: Apply any relevant fixes from libvirt's repositories if this is a known issue, and thoroughly test to confirm the problem is resolved.

By focusing on these areas, you should be able to identify the root cause and implement a fix to ensure the original device remains attached upon swap_volume failure.